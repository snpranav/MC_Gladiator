{
  "buffer_size": 100000,
  "compress_observations": true,
  "double_q": false,
  "dueling": false,
  "env": "1v1env",
  "framework": "torch",
  "gamma": 0.99,
  "hiddens": [],
  "learning_starts": 1000,
  "model": {
    "custom_model": "cnet",
    "custom_model_config": {}
  },
  "multiagent": {
    "policies": {
      "policy_01": [
        null,
        "Box([[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]], [[[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]\n\n [[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]\n\n [[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]], (3, 64, 64), float32)",
        "Discrete(7)",
        {}
      ],
      "policy_02": [
        null,
        "Box([[[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]\n\n [[0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  ...\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]\n  [0. 0. 0. ... 0. 0. 0.]]], [[[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]\n\n [[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]\n\n [[255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  ...\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]\n  [255. 255. 255. ... 255. 255. 255.]]], (3, 64, 64), float32)",
        "Discrete(7)",
        {}
      ]
    },
    "policies_to_train": [
      "policy_01"
    ],
    "policy_mapping_fn": "<function <lambda> at 0x7f1aa4235e60>"
  },
  "num_gpus": 2,
  "num_workers": 2,
  "train_batch_size": 256
}